{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d4acdd9",
   "metadata": {},
   "source": [
    "## Image -> Text Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a86203",
   "metadata": {},
   "source": [
    "Goal: Set up a pipeline to Claude to identify non-text parts of the image (shape, icongraphy, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb88933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having errors? Want to see the code? Look at llm_helper functions! \n",
    "from llm_helper_functions import *\n",
    "\n",
    "#TODO\n",
    "#\n",
    "# Run / Test / Find Errors\n",
    "    # Edit the transcription prompt to add ? for unknown characters? \n",
    "# Include a file size check somewhere in processing images\n",
    "# Better Error Handleing in the final functions\n",
    "\n",
    "# Look into OCR\n",
    "# Edit last function to take the OCR Transcription \n",
    "\n",
    "# Go take more pictures\n",
    "# Make the API Set up thing better / include constants for those paths as well "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab88ee2c",
   "metadata": {},
   "source": [
    "### Folder and API Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78113217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note there is a 5MB limit on images\n",
    "# It took 5 minutes to run 38 images\n",
    "INPUT_FOLDER = \"../data/examples/\" # TODO change to ..data/input/\n",
    "OUTPUT_FOLDER = \"../data/output/\"\n",
    "OUTPUT_FILENAME = \"results.csv\"\n",
    "\n",
    "API_KEY = get_api_key(\"credentials.txt\")\n",
    "HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"x-api-key\": API_KEY,\n",
    "    \"anthropic-version\": \"2023-06-01\"\n",
    "}\n",
    "MODEL = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8022428f",
   "metadata": {},
   "source": [
    "### Prompts:\n",
    "Feel free to change or add more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c612ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of these prompts will be accompanied by an image\n",
    "ICON_PROMPT = \"Hi! Can you identify the iconography of this gravestone? Most of the icongraphy should be towards the top of the stone. \" \\\n",
    "\"If there is no icongoraphy, just say None. Please only return exactly what the iconography is. Do not say anything else in your answer.\"\n",
    "\n",
    "SHAPE_PROMPT = \"Hi! Can you identify the shape of this gravestone? Please only return exactly what the shape is. Do not say anything else in your answer.\"\n",
    "\n",
    "MATERIAL_PROMPT = \"Hi! Can you tell me which material this gravestone is made of? It should be one of granite, marble, or slate. \" \\\n",
    "\"Please only return exactly what the material is. Do not say anything else in your answer.\" \n",
    "\n",
    "TRANSCRIPTION_PROMPT = \"Hi! Can you transcribe the text on this gravestone? Please deliminate each line of the transcription with a hyphen. \" \\\n",
    "\"Please only return the transcription. Do not say anything else in your answer.\"\n",
    "\n",
    "YOUR_PROMPT_HERE = \"\"\n",
    "\n",
    "# You can add your prompt variable and corresponding column here\n",
    "PROMPTS = [ICON_PROMPT, SHAPE_PROMPT, MATERIAL_PROMPT, TRANSCRIPTION_PROMPT] # Dont put the info prompt in here\n",
    "COLUMNS = [\"Image Name\", \"Iconography Description\", \"Shape Description\", \"Material\", \"Claude Transcription\"] # Don't change first/last column order\n",
    "\n",
    "# Separate Task to translate the transcription\n",
    "INFO_PROMPT = \"Hi! The following is a transcription from a gravestone. Each line is separated by a newline character.\" \\\n",
    "\"Can you tell me the first name, middle name, last name, date of birth, date of death, age at death, and the text of the epitaph?\" \\\n",
    "\"It is common that not all of this information will be present. For any field that is not there, say 'None'. Please only return exactly \" \\\n",
    "\"the information requested, in order separated by a comma. Do not say anything else in your answer. Here is the Transcription: \"\n",
    "\n",
    "INFO_COLUMNS = [\"First Name\", \"Middle Name\", \"Last Name\", \"Date of Birth\", \"Date of Death\", \"Age at Death\", \"Epitaph Text\", \"Claude Transcription\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe09a35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gravestone_desc(input_folder, prompts, columns, headers, debug=False):\n",
    "    \"\"\"\n",
    "    Uses the helper function to get all the names of the images, then calls claude with each prompt for each image.\n",
    "    Puts all the information for each image in a row of a dataframe.\n",
    "    \n",
    "    Args:\n",
    "        input_folder str: Folder path with the images\n",
    "        prompts list(str): List of User-Specified Prompts for Claude\n",
    "        columns list(str): Corresponding list of columns to store the results of the above prompts\n",
    "        debug boolean: Debug mode. Turn on if you encounter errors and want to see the full debug message from anthropic. \n",
    "    Returns:\n",
    "        df(DataFrame): Dataframe with the columns specified in columns\n",
    "    \"\"\"\n",
    "\n",
    "    files = list_files_in_folder(input_folder)\n",
    "    all_results = []\n",
    "\n",
    "    for image in files:\n",
    "\n",
    "        image_result = [image]\n",
    "        for prompt in prompts:\n",
    "        # Call Claude\n",
    "                \n",
    "            result = call_claude(prompt, headers=headers, image_path=input_folder + image, debug=debug)\n",
    "            image_result.append(result['content'][0]['text'])\n",
    "        # Extract Text\n",
    "        all_results.append(image_result)\n",
    "\n",
    "    # Put in a dataframe and return \n",
    "    df = pd.DataFrame(all_results, columns=columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def transcription_info(transcriptions, prompt, columns, headers, debug=False):\n",
    "    \"\"\"\n",
    "    Uses the helper function to get all the names of the images, then calls claude with each prompt for each image.\n",
    "    Puts all the information for each image in a row of a dataframe.\n",
    "    \n",
    "    Args:\n",
    "        input_folder str: Folder path with the images\n",
    "        prompts list(str): List of User-Specified Prompts for Claude\n",
    "        columns list(str): Corresponding list of columns to store the results of the above prompts\n",
    "        debug boolean: Debug mode. Turn on if you encounter errors and want to see the full debug message from anthropic. \n",
    "    Returns:\n",
    "        df(DataFrame): Dataframe with the columns specified in columns. \n",
    "    \"\"\"\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for trans in transcriptions:\n",
    "\n",
    "        # Call Claude\n",
    "        result = call_claude(prompt + trans, headers=headers, debug=debug)\n",
    "\n",
    "        # Split on commas: (#TODO Error Handleing)\n",
    "        result = str.split((result['content'][0]['text']), \",\")\n",
    "        \n",
    "        # Basic Error Handleing for now \n",
    "        if len(result) != len(columns):\n",
    "            result = [None] * len(columns)\n",
    "\n",
    "        result.append(trans) # Include the transcription for joining purpose later\n",
    "\n",
    "        all_results.append(result)\n",
    "\n",
    "    # Put in a dataframe and return \n",
    "    df = pd.DataFrame(all_results, columns=columns)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cd6e3",
   "metadata": {},
   "source": [
    "### Run the code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09d18545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error response: {\"type\":\"error\",\"error\":{\"type\":\"overloaded_error\",\"message\":\"Overloaded\"}}\n",
      "Error calling API: 529 Server Error:  for url: https://api.anthropic.com/v1/messages\n",
      "Response status: 529\n",
      "Response text: {\"type\":\"error\",\"error\":{\"type\":\"overloaded_error\",\"message\":\"Overloaded\"}}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_desc \u001b[38;5;241m=\u001b[39m \u001b[43mgravestone_desc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_FOLDER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPROMPTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOLUMNS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHEADERS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_desc\u001b[38;5;241m.\u001b[39mto_csv(OUTPUT_FOLDER \u001b[38;5;241m+\u001b[39m OUTPUT_FILENAME)\n\u001b[1;32m      4\u001b[0m df_desc\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36mgravestone_desc\u001b[0;34m(input_folder, prompts, columns, headers, debug)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Call Claude\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     result \u001b[38;5;241m=\u001b[39m call_claude(prompt, headers\u001b[38;5;241m=\u001b[39mheaders, image_path\u001b[38;5;241m=\u001b[39minput_folder \u001b[38;5;241m+\u001b[39m image, debug\u001b[38;5;241m=\u001b[39mdebug)\n\u001b[0;32m---> 25\u001b[0m     image_result\u001b[38;5;241m.\u001b[39mappend(\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Extract Text\u001b[39;00m\n\u001b[1;32m     27\u001b[0m all_results\u001b[38;5;241m.\u001b[39mappend(image_result)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "df_desc = gravestone_desc(INPUT_FOLDER, PROMPTS, COLUMNS, HEADERS, debug=False)\n",
    "df_desc.to_csv(OUTPUT_FOLDER + OUTPUT_FILENAME)\n",
    "\n",
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d885b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = transcription_info(df_desc[\"Claude Transcription\"], INFO_PROMPT, INFO_COLUMNS, HEADERS, debug=False)\n",
    "df_all = pd.concat([df_desc, df_info])\n",
    "df_all.to_csv(OUTPUT_FOLDER + OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41044495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
