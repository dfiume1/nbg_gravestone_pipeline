{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d4acdd9",
   "metadata": {},
   "source": [
    "## Image -> Text Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a86203",
   "metadata": {},
   "source": [
    "Goal: Set up a pipeline to Claude to identify non-text parts of the image (shape, icongraphy, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb88933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having errors? Want to see the code? Look at llm_helper functions! \n",
    "from llm_helper_functions import *\n",
    "\n",
    "#TODO\n",
    "#\n",
    "# Run / Test / Find Errors\n",
    "    # Edit the transcription prompt to add ? for unknown characters? \n",
    "\n",
    "# Better Error Handleing in the final functions\n",
    "\n",
    "# Look into OCR\n",
    "# Edit last function to take the OCR Transcription \n",
    "\n",
    "# Go take more pictures\n",
    "# Make the API Set up thing better / include constants for those paths as well "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab88ee2c",
   "metadata": {},
   "source": [
    "### Folder and API Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78113217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note there is a 5MB limit on images\n",
    "# It took 5 minutes to run 38 images\n",
    "INPUT_FOLDER = \"../data/input/\" # TODO change to ..data/input/\n",
    "OUTPUT_FOLDER = \"../data/output/\"\n",
    "OUTPUT_FILENAME = \"results.csv\"\n",
    "\n",
    "API_KEY = get_api_key(\"credentials.txt\")\n",
    "HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"x-api-key\": API_KEY,\n",
    "    \"anthropic-version\": \"2023-06-01\"\n",
    "}\n",
    "MODEL = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8022428f",
   "metadata": {},
   "source": [
    "### Prompts:\n",
    "Feel free to change or add more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c612ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of these prompts will be accompanied by an image\n",
    "ICON_PROMPT = \"Hi! Can you identify the iconography of this gravestone? Most of the icongraphy should be towards the top of the stone. \" \\\n",
    "\"If there is no icongoraphy, just say None. Please only return exactly what the iconography is. Do not say anything else in your answer.\"\n",
    "\n",
    "SHAPE_PROMPT = \"Hi! Can you identify the shape of this gravestone? Please only return exactly what the shape is. Do not say anything else in your answer.\"\n",
    "\n",
    "MATERIAL_PROMPT = \"Hi! Can you tell me which material this gravestone is made of? It should be one of granite, marble, or slate. \" \\\n",
    "\"Please only return exactly what the material is. Do not say anything else in your answer.\" \n",
    "\n",
    "TRANSCRIPTION_PROMPT = \"Hi! Can you transcribe the text on this gravestone? Please deliminate each line of the transcription with a hyphen. \" \\\n",
    "\"Please only return the transcription. Do not say anything else in your answer.\"\n",
    "\n",
    "YOUR_PROMPT_HERE = \"\"\n",
    "\n",
    "# You can add your prompt variable and corresponding column here\n",
    "PROMPTS = [ICON_PROMPT, SHAPE_PROMPT, MATERIAL_PROMPT, TRANSCRIPTION_PROMPT] # Dont put the info prompt in here\n",
    "COLUMNS = [\"Image Name\", \"Iconography Description\", \"Shape Description\", \"Material\", \"Claude Transcription\"] # Don't change first/last column order\n",
    "\n",
    "# Separate Task to translate the transcription\n",
    "INFO_PROMPT = \"Hi! The following is a transcription from a gravestone. Each line is separated by a newline character.\" \\\n",
    "\"Can you tell me the first name, middle name, last name, date of birth, date of death, age at death.\" \\\n",
    "\"The information will not be labeled. You might have to calculate age on death. If there is information missing for a field, put None. Please only return exactly \" \\\n",
    "\"the information requested, in order separated by a comma. Do not say anything else in your answer. Here is the Transcription: \"\n",
    "\n",
    "INFO_COLUMNS = [\"First Name\", \"Middle Name\", \"Last Name\", \"Date of Birth\", \"Date of Death\", \"Age at Death\", \"Claude Transcription\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe09a35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gravestone_desc(input_folder, prompts, columns, headers, debug=False):\n",
    "    \"\"\"\n",
    "    Uses the helper function to get all the names of the images, then calls claude with each prompt for each image.\n",
    "    Puts all the information for each image in a row of a dataframe.\n",
    "    \n",
    "    Args:\n",
    "        input_folder str: Folder path with the images\n",
    "        prompts list(str): List of User-Specified Prompts for Claude\n",
    "        columns list(str): Corresponding list of columns to store the results of the above prompts\n",
    "        debug boolean: Debug mode. Turn on if you encounter errors and want to see the full debug message from anthropic. \n",
    "    Returns:\n",
    "        df(DataFrame): Dataframe with the columns specified in columns\n",
    "    \"\"\"\n",
    "\n",
    "    files = list_files_in_folder(input_folder)\n",
    "    all_results = []\n",
    "\n",
    "    for image in files:\n",
    "\n",
    "        image_result = [image]\n",
    "        for prompt in prompts:\n",
    "        # Call Claude\n",
    "                \n",
    "            result = call_claude(prompt, headers=headers, image_path=input_folder + image, debug=debug)\n",
    "            image_result.append(result['content'][0]['text'])\n",
    "        # Extract Text\n",
    "        all_results.append(image_result)\n",
    "\n",
    "    # Put in a dataframe and return \n",
    "    df = pd.DataFrame(all_results, columns=columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def transcription_info(transcriptions, prompt, columns, headers, debug=False):\n",
    "    \"\"\"\n",
    "    Uses the helper function to get all the names of the images, then calls claude with each prompt for each image.\n",
    "    Puts all the information for each image in a row of a dataframe.\n",
    "    \n",
    "    Args:\n",
    "        input_folder str: Folder path with the images\n",
    "        prompts list(str): List of User-Specified Prompts for Claude\n",
    "        columns list(str): Corresponding list of columns to store the results of the above prompts\n",
    "        debug boolean: Debug mode. Turn on if you encounter errors and want to see the full debug message from anthropic. \n",
    "    Returns:\n",
    "        df(DataFrame): Dataframe with the columns specified in columns. \n",
    "    \"\"\"\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for trans in transcriptions:\n",
    "\n",
    "        # Call Claude\n",
    "        result = call_claude(prompt + trans, headers=headers, debug=debug)\n",
    "\n",
    "        print(prompt + trans)\n",
    "\n",
    "        # Split on commas: (#TODO Error Handleing)\n",
    "        result = str.split((result['content'][0]['text']), \",\")\n",
    "\n",
    "\n",
    "        print(result)\n",
    "\n",
    "        result.append(trans) # Include the transcription for joining purpose later\n",
    "\n",
    "        all_results.append(result)\n",
    "\n",
    "    # Put in a dataframe and return \n",
    "    df = pd.DataFrame(all_results, columns=columns)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cd6e3",
   "metadata": {},
   "source": [
    "### Run the code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09d18545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Name</th>\n",
       "      <th>Iconography Description</th>\n",
       "      <th>Shape Description</th>\n",
       "      <th>Material</th>\n",
       "      <th>Claude Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_DSC0470.jpeg</td>\n",
       "      <td>None</td>\n",
       "      <td>Rectangle</td>\n",
       "      <td>Granite</td>\n",
       "      <td>ELLEN H. CUNLIFF\\n-\\nDAUGHTER OF\\n-\\nJOSEPH &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_DSC0469.jpeg</td>\n",
       "      <td>None</td>\n",
       "      <td>Rectangle</td>\n",
       "      <td>Granite</td>\n",
       "      <td>MARY E. CUNLIFF\\n-\\nWIFE OF\\n-\\nSYLVANUS G. BU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Image Name Iconography Description Shape Description Material  \\\n",
       "0  _DSC0470.jpeg                    None         Rectangle  Granite   \n",
       "1  _DSC0469.jpeg                    None         Rectangle  Granite   \n",
       "\n",
       "                                Claude Transcription  \n",
       "0  ELLEN H. CUNLIFF\\n-\\nDAUGHTER OF\\n-\\nJOSEPH & ...  \n",
       "1  MARY E. CUNLIFF\\n-\\nWIFE OF\\n-\\nSYLVANUS G. BU...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc = gravestone_desc(INPUT_FOLDER, PROMPTS, COLUMNS, HEADERS, debug=False)\n",
    "df_desc.to_csv(OUTPUT_FOLDER + OUTPUT_FILENAME)\n",
    "\n",
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ae1306d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Name</th>\n",
       "      <th>Iconography Description</th>\n",
       "      <th>Shape Description</th>\n",
       "      <th>Material</th>\n",
       "      <th>Claude Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_DSC0470.jpeg</td>\n",
       "      <td>None</td>\n",
       "      <td>Rectangle</td>\n",
       "      <td>Granite</td>\n",
       "      <td>ELLEN H. CUNLIFF\\n-\\nDAUGHTER OF\\n-\\nJOSEPH &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_DSC0469.jpeg</td>\n",
       "      <td>None</td>\n",
       "      <td>Rectangle</td>\n",
       "      <td>Granite</td>\n",
       "      <td>MARY E. CUNLIFF\\n-\\nWIFE OF\\n-\\nSYLVANUS G. BU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Image Name Iconography Description Shape Description Material  \\\n",
       "0  _DSC0470.jpeg                    None         Rectangle  Granite   \n",
       "1  _DSC0469.jpeg                    None         Rectangle  Granite   \n",
       "\n",
       "                                Claude Transcription  \n",
       "0  ELLEN H. CUNLIFF\\n-\\nDAUGHTER OF\\n-\\nJOSEPH & ...  \n",
       "1  MARY E. CUNLIFF\\n-\\nWIFE OF\\n-\\nSYLVANUS G. BU...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d885b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! The following is a transcription from a gravestone. Each line is separated by a newline character.Can you tell me the first name, middle name, last name, date of birth, date of death, age at death.The information will not be labeled. You might have to calculate age on death. If there is information missing for a field, put None. Please only return exactly the information requested, in order separated by a comma. Do not say anything else in your answer. Here is the Transcription: ELLEN H. CUNLIFF\n",
      "-\n",
      "DAUGHTER OF\n",
      "-\n",
      "JOSEPH & MARY M.\n",
      "-\n",
      "CUNLIFF\n",
      "-\n",
      "1815 - 1907\n",
      "['ELLEN', ' H.', ' CUNLIFF', ' 1815', ' 1907', ' 92']\n",
      "Hi! The following is a transcription from a gravestone. Each line is separated by a newline character.Can you tell me the first name, middle name, last name, date of birth, date of death, age at death.The information will not be labeled. You might have to calculate age on death. If there is information missing for a field, put None. Please only return exactly the information requested, in order separated by a comma. Do not say anything else in your answer. Here is the Transcription: MARY E. CUNLIFF\n",
      "-\n",
      "WIFE OF\n",
      "-\n",
      "SYLVANUS G. BULLOCK\n",
      "-\n",
      "SEPT. 28 1839\n",
      "-\n",
      "JUNE 14 1924\n",
      "['Mary', ' E.', ' Cunliff', ' September 28 1839', ' June 14 1924', ' 84']\n"
     ]
    }
   ],
   "source": [
    "df_info = transcription_info(df_desc[\"Claude Transcription\"], INFO_PROMPT, INFO_COLUMNS, HEADERS, debug=False)\n",
    "df_all = pd.concat([df_desc, df_info])\n",
    "df_all.to_csv(OUTPUT_FOLDER + OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d6902a",
   "metadata": {},
   "source": [
    "## OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a7bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting easyocr\n",
      "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.5 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (0.17.2)\n",
      "Collecting opencv-python-headless (from easyocr)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-macosx_13_0_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: scipy in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (1.14.1)\n",
      "Requirement already satisfied: numpy in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (2.2.6)\n",
      "Requirement already satisfied: Pillow in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (10.4.0)\n",
      "Collecting scikit-image (from easyocr)\n",
      "  Downloading scikit_image-0.25.2-cp312-cp312-macosx_10_13_x86_64.whl.metadata (14 kB)\n",
      "Collecting python-bidi (from easyocr)\n",
      "  Downloading python_bidi-0.6.6-cp312-cp312-macosx_10_12_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: PyYAML in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (6.0.2)\n",
      "Collecting Shapely (from easyocr)\n",
      "  Downloading shapely-2.1.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting pyclipper (from easyocr)\n",
      "  Downloading pyclipper-1.3.0.post6-cp312-cp312-macosx_10_13_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting ninja (from easyocr)\n",
      "  Downloading ninja-1.11.1.4-py3-none-macosx_10_9_universal2.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: filelock in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (2024.9.0)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->easyocr)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->easyocr)\n",
      "  Downloading tifffile-2025.6.11-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: packaging>=21 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from scikit-image->easyocr) (24.1)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->easyocr)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from jinja2->torch->easyocr) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from sympy->torch->easyocr) (1.3.0)\n",
      "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-macosx_10_9_universal2.whl (279 kB)\n",
      "Downloading opencv_python_headless-4.12.0.88-cp37-abi3-macosx_13_0_x86_64.whl (57.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.3/57.3 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp312-cp312-macosx_10_13_x86_64.whl (143 kB)\n",
      "Downloading python_bidi-0.6.6-cp312-cp312-macosx_10_12_x86_64.whl (267 kB)\n",
      "Downloading scikit_image-0.25.2-cp312-cp312-macosx_10_13_x86_64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.1.1-cp312-cp312-macosx_10_13_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading tifffile-2025.6.11-py3-none-any.whl (230 kB)\n",
      "Installing collected packages: python-bidi, pyclipper, tifffile, Shapely, opencv-python-headless, ninja, lazy-loader, imageio, scikit-image, easyocr\n",
      "Successfully installed Shapely-2.1.1 easyocr-1.7.2 imageio-2.37.0 lazy-loader-0.4 ninja-1.11.1.4 opencv-python-headless-4.12.0.88 pyclipper-1.3.0.post6 python-bidi-0.6.6 scikit-image-0.25.2 tifffile-2025.6.11\n",
      "Processing _DSC0470.jpeg...\n",
      "Processing _DSC0469.jpeg...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import easyocr\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "    \n",
    "\n",
    "def preprocess_ocr(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Histogram Equalization to enhance contrast\n",
    "    image = cv2.equalizeHist(image)\n",
    "\n",
    "    # Denoise\n",
    "    image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "\n",
    "    # Adaptive or OTSU thresholding\n",
    "    _, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Morphological closing to solidify letters\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return thresh\n",
    "\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    try:\n",
    "        preprocessed = preprocess_ocr(image_path)\n",
    "        # Convert back to PIL for pytesseract\n",
    "        pil_img = Image.fromarray(preprocessed)\n",
    "\n",
    "        # Sanity check\n",
    "        cv2.imwrite(\"debug_output.png\", preprocessed)\n",
    "\n",
    "        # Try different Page Segmentation Mode (PSM)\n",
    "        custom_config =  r'--oem 3 --psm 11 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.-+ '\n",
    "        text = pytesseract.image_to_string(pil_img, config=custom_config, lang='eng')\n",
    "        return text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error processing {image_path}: {e}\"\n",
    "\n",
    "def process_gravestone_images(folder_path):\n",
    "    results = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp')):\n",
    "            full_path = os.path.join(folder_path, filename)\n",
    "            print(f\"Processing {filename}...\")\n",
    "            text = extract_text_from_image(full_path)\n",
    "            results.append({\"Image Name\": filename, \"OCR Transcription\": text})\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df \n",
    "\n",
    "\n",
    "df = process_gravestone_images(INPUT_FOLDER)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310a6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: easyocr 1.7.2\n",
      "Uninstalling easyocr-1.7.2:\n",
      "  Successfully uninstalled easyocr-1.7.2\n",
      "Collecting easyocr\n",
      "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.5 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (0.17.2)\n",
      "Requirement already satisfied: opencv-python-headless in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (4.12.0.88)\n",
      "Requirement already satisfied: scipy in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (1.14.1)\n",
      "Requirement already satisfied: numpy in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (2.3.2)\n",
      "Requirement already satisfied: Pillow in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (10.4.0)\n",
      "Requirement already satisfied: scikit-image in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (0.25.2)\n",
      "Requirement already satisfied: python-bidi in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (0.6.6)\n",
      "Requirement already satisfied: PyYAML in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (6.0.2)\n",
      "Requirement already satisfied: Shapely in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (2.1.1)\n",
      "Requirement already satisfied: pyclipper in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (1.11.1.4)\n",
      "Requirement already satisfied: filelock in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (2024.9.0)\n",
      "Collecting numpy (from easyocr)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from scikit-image->easyocr) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from scikit-image->easyocr) (2025.6.11)\n",
      "Requirement already satisfied: packaging>=21 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from scikit-image->easyocr) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from jinja2->torch->easyocr) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from sympy->torch->easyocr) (1.3.0)\n",
      "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp312-cp312-macosx_14_0_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, easyocr\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.2\n",
      "    Uninstalling numpy-2.3.2:\n",
      "      Successfully uninstalled numpy-2.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.16.2 requires numpy<2.0.0,>=1.26.0; python_version >= \"3.12\", but you have numpy 2.2.6 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed easyocr-1.7.2 numpy-2.2.6\n",
      "Processing _DSC0470.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df \n\u001b[0;32m---> 67\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_gravestone_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_FOLDER\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 61\u001b[0m, in \u001b[0;36mprocess_gravestone_images\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     59\u001b[0m         full_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, filename)\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[43measy_ocr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage Name\u001b[39m\u001b[38;5;124m\"\u001b[39m: filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOCR Transcription\u001b[39m\u001b[38;5;124m\"\u001b[39m: text})\n\u001b[1;32m     64\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "Cell \u001b[0;32mIn[10], line 45\u001b[0m, in \u001b[0;36measy_ocr\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Run EasyOCR on the preprocessed image\u001b[39;00m\n\u001b[1;32m     44\u001b[0m reader \u001b[38;5;241m=\u001b[39m easyocr\u001b[38;5;241m.\u001b[39mReader([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m], gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 45\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Extract and print detected text\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müîé OCR Output:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/data1030/lib/python3.12/site-packages/easyocr/easyocr.py:456\u001b[0m, in \u001b[0;36mReader.readtext\u001b[0;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03mimage: file path or numpy-array or a byte stream object\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    454\u001b[0m img, img_cv_grey \u001b[38;5;241m=\u001b[39m reformat_input(image)\n\u001b[0;32m--> 456\u001b[0m horizontal_list, free_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mslope_ths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mslope_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mycenter_ths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mycenter_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mheight_ths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mheight_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth_ths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwidth_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43madd_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43madd_margin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreformat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001b[39;00m\n\u001b[1;32m    467\u001b[0m horizontal_list, free_list \u001b[38;5;241m=\u001b[39m horizontal_list[\u001b[38;5;241m0\u001b[39m], free_list[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/data1030/lib/python3.12/site-packages/easyocr/easyocr.py:321\u001b[0m, in \u001b[0;36mReader.detect\u001b[0;34m(self, img, min_size, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, add_margin, reformat, optimal_num_chars, threshold, bbox_min_score, bbox_min_size, max_candidates)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reformat:\n\u001b[1;32m    319\u001b[0m     img, img_cv_grey \u001b[38;5;241m=\u001b[39m reformat_input(img)\n\u001b[0;32m--> 321\u001b[0m text_box_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_textbox\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moptimal_num_chars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimal_num_chars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m horizontal_list_agg, free_list_agg \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_box \u001b[38;5;129;01min\u001b[39;00m text_box_list:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/data1030/lib/python3.12/site-packages/easyocr/detection.py:95\u001b[0m, in \u001b[0;36mget_textbox\u001b[0;34m(detector, image, canvas_size, mag_ratio, text_threshold, link_threshold, low_text, poly, device, optimal_num_chars, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     94\u001b[0m estimate_num_chars \u001b[38;5;241m=\u001b[39m optimal_num_chars \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m bboxes_list, polys_list \u001b[38;5;241m=\u001b[39m \u001b[43mtest_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimate_num_chars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimate_num_chars:\n\u001b[1;32m    100\u001b[0m     polys_list \u001b[38;5;241m=\u001b[39m [[p \u001b[38;5;28;01mfor\u001b[39;00m p, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(polys, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mabs\u001b[39m(optimal_num_chars \u001b[38;5;241m-\u001b[39m x[\u001b[38;5;241m1\u001b[39m]))]\n\u001b[1;32m    101\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m polys \u001b[38;5;129;01min\u001b[39;00m polys_list]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/data1030/lib/python3.12/site-packages/easyocr/detection.py:41\u001b[0m, in \u001b[0;36mtest_net\u001b[0;34m(canvas_size, mag_ratio, net, image, text_threshold, link_threshold, low_text, poly, device, estimate_num_chars)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# preprocessing\u001b[39;00m\n\u001b[1;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mtranspose(normalizeMeanVariance(n_img), (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     40\u001b[0m      \u001b[38;5;28;01mfor\u001b[39;00m n_img \u001b[38;5;129;01min\u001b[39;00m img_resized_list]\n\u001b[0;32m---> 41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# Trying out EasyOCR\n",
    "import cv2\n",
    "import pytesseract\n",
    "import easyocr\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "!pip uninstall easyocr -y\n",
    "!pip install easyocr --no-cache-dir\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def preprocess_for_easyocr(image_path):\n",
    "    # Grayscale\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Enhance Contrast\n",
    "    img_eq = cv2.equalizeHist(img)\n",
    "\n",
    "    # Gaussian Blur to reduce noise\n",
    "    img_blur = cv2.GaussianBlur(img_eq, (3, 3), 0)\n",
    "\n",
    "    # Otsu‚Äôs Thresholding (better than adaptive here)\n",
    "    _, thresh = cv2.threshold(img_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Morphological closing to fix broken letters\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return morph\n",
    "\n",
    "\n",
    "def easy_ocr(image_path):\n",
    "    # Preprocess the image\n",
    "    preprocessed = preprocess_for_easyocr(image_path)\n",
    "\n",
    "    # Save or display preprocessed result for sanity check\n",
    "    debug_path = OUTPUT_FOLDER + \"preprocessed_easyocr.png\"\n",
    "    cv2.imwrite(debug_path, preprocessed)\n",
    "\n",
    "    # Run EasyOCR on the preprocessed image\n",
    "    reader = easyocr.Reader(['en'], gpu=False)\n",
    "    result = reader.readtext(preprocessed)\n",
    "\n",
    "    # Extract and print detected text\n",
    "    print(\"\\nüîé OCR Output:\")\n",
    "    for detection in result:\n",
    "        bbox, text, conf = detection\n",
    "        print(f\"{text} (Confidence: {conf:.2f})\")\n",
    "\n",
    "\n",
    "def process_gravestone_images(folder_path):\n",
    "    results = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp')):\n",
    "            full_path = os.path.join(folder_path, filename)\n",
    "            print(f\"Processing {filename}...\")\n",
    "            text = easy_ocr(full_path)\n",
    "            results.append({\"Image Name\": filename, \"OCR Transcription\": text})\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df \n",
    "\n",
    "df = process_gravestone_images(INPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "41044495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Name</th>\n",
       "      <th>OCR Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_DSC0470.jpeg</td>\n",
       "      <td>Ellzak CW_iFF\\nDAUCATER\\n2 7\\nJosE?H&amp;MaRy\\nM\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_DSC0469.jpeg</td>\n",
       "      <td>EQWLifF\\nWPz\\n0F\\nYLVANUS G. BuLlCch\\nSEPT 284...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Image Name                                  OCR Transcription\n",
       "0  _DSC0470.jpeg  Ellzak CW_iFF\\nDAUCATER\\n2 7\\nJosE?H&MaRy\\nM\\n...\n",
       "1  _DSC0469.jpeg  EQWLifF\\nWPz\\n0F\\nYLVANUS G. BuLlCch\\nSEPT 284..."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(OUTPUT_FOLDER + \"ocr_results.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10da66c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
