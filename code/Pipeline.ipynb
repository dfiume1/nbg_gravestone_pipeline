{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d4acdd9",
   "metadata": {},
   "source": [
    "## NBG Gravestone Image Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a86203",
   "metadata": {},
   "source": [
    "Goal: Set up a pipeline to Claude to identify non-text parts of the image (shape, icongraphy, etc) as well as OCR to extract key text and information such as name, birth and death dates, and age. \n",
    "\n",
    "Currently, the model costs about 1.7 cents and takes around 20 seconds per image. Both of these could be reduced in the future (combining the prompts would use slightly less tokens and many requests, but may require a trade off in accuracy). Switching LLM's could also result in this. \n",
    "\n",
    "To use the pipeline, make sure you are following instructions in the README and here - once you've set up your environment and API Key, you should be able to just run these cells with your images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eb88933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having errors? Want to see the code? Look at llm_helper functions! \n",
    "from llm_helper_functions import *\n",
    "from ocr_helper_functions import * \n",
    "\n",
    "#TODO\n",
    "#\n",
    "# Run / Test / Find Errors\n",
    "    # Edit the transcription prompt to add ? for unknown characters? \n",
    "    # Needs Error checking to save data even if something goes wrong \n",
    "\n",
    "# Make the API Set up thing better / include constants for those paths as well "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab88ee2c",
   "metadata": {},
   "source": [
    "### Folder and API Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78113217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note there is a 5MB limit on images\n",
    "INPUT_FOLDER = \"../data/input/\" # TODO change to ..data/input/\n",
    "OUTPUT_FOLDER = \"../data/output/\"\n",
    "OUTPUT_FILENAME = \"results.csv\"\n",
    "\n",
    "API_KEY = get_api_key(\"credentials.txt\") \n",
    "HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"x-api-key\": API_KEY,\n",
    "    \"anthropic-version\": \"2023-06-01\"\n",
    "}\n",
    "MODEL = \"\" #TODO Allow to more easily change out models, for now you have to go to llm_helper_functions to change it "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8022428f",
   "metadata": {},
   "source": [
    "### Prompts:\n",
    "Feel free to change or add more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c612ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of these prompts will be accompanied by the image\n",
    "ICON_PROMPT = \"Hi! Can you identify the iconography of this gravestone? Most of the icongraphy should be towards the top of the stone. \" \\\n",
    "\"If there is no icongoraphy, just say None. Please only return exactly what the iconography is. Do not say anything else in your answer.\"\n",
    "\n",
    "SHAPE_PROMPT = \"Hi! Can you identify the shape of this gravestone? Common shapes are Square Top, Check Top, Ogee, Arc Top, Arc Top with Shoulders, \" \\\n",
    "\"Half-Round, Half Ogee, Arc Top with Scotia Shoulders, and Peon Top Please only return exactly what the shape is. Do not say anything else in your answer.\"\n",
    "\n",
    "MATERIAL_PROMPT = \"Hi! Can you tell me which material this gravestone is made of? It should be one of granite, marble, or slate. \" \\\n",
    "\"Please only return exactly what the material is. Do not say anything else in your answer.\" \n",
    "\n",
    "TRANSCRIPTION_PROMPT = \"Hi! Can you transcribe the text on this gravestone? Please deliminate each line of the transcription with a hyphen. \" \\\n",
    "\"Please only return the transcription. Do not say anything else in your answer.\"\n",
    "\n",
    "YOUR_PROMPT_HERE = \"\"\n",
    "\n",
    "# You can add your prompt variable and corresponding column here\n",
    "PROMPTS = [ICON_PROMPT, SHAPE_PROMPT, MATERIAL_PROMPT, TRANSCRIPTION_PROMPT] # Dont put the info prompt in here\n",
    "COLUMNS = [\"Image Name\", \"Iconography Description\", \"Shape Description\", \"Material\", \"Claude Transcription\"] # Don't change first/last column order\n",
    "\n",
    "# Separate Task to translate the transcription\n",
    "INFO_PROMPT = \"Hi! The following is a transcription from a gravestone. Each line is separated by a newline character.\" \\\n",
    "\"Can you tell me the first name, middle name, last name, date of birth, date of death, age at death.\" \\\n",
    "\"The information will not be labeled. You might have to calculate age on death, birth year, or death year based on the other two. If there is information missing for a field, put None. Please only return exactly \" \\\n",
    "\"the information requested, in order separated by a comma. Only do this for the first person if there are multiple. Do not say anything else in your answer. Here is the Transcription: \"\n",
    "\n",
    "# You can add info to extract here if you change the prompt above \n",
    "INFO_COLUMNS = [\"First Name\", \"Middle Name\", \"Last Name\", \"Date of Birth\", \"Date of Death\", \"Age at Death\", \"Claude Transcription\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cd6e3",
   "metadata": {},
   "source": [
    "### Claude Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d18545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi2\n",
      "hi\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_desc \u001b[38;5;241m=\u001b[39m \u001b[43mgravestone_desc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_FOLDER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPROMPTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOLUMNS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHEADERS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_desc\u001b[38;5;241m.\u001b[39mto_csv(OUTPUT_FOLDER \u001b[38;5;241m+\u001b[39m OUTPUT_FILENAME)\n\u001b[1;32m      4\u001b[0m df_desc\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[39], line 33\u001b[0m, in \u001b[0;36mgravestone_desc\u001b[0;34m(input_folder, prompts, columns, headers, debug, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m attempt \u001b[38;5;241m<\u001b[39m max_retries:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcall_claude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;129;01mand\u001b[39;00m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     36\u001b[0m             result_text \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/DSI/2050/nbg_gravestone_pipeline/code/llm_helper_functions.py:124\u001b[0m, in \u001b[0;36mcall_claude\u001b[0;34m(prompt, headers, image_path, model, debug)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03mCall Claude API with a message and optional image\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    dict: API response\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# For Rate Limiting Purposes \u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Set content to the prompt\u001b[39;00m\n\u001b[1;32m    128\u001b[0m content \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_desc = gravestone_desc(INPUT_FOLDER, PROMPTS, COLUMNS, HEADERS, debug=False)\n",
    "df_desc.to_csv(OUTPUT_FOLDER + OUTPUT_FILENAME, index=False)\n",
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ae1306d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Name</th>\n",
       "      <th>Iconography Description</th>\n",
       "      <th>Shape Description</th>\n",
       "      <th>Material</th>\n",
       "      <th>Claude Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_DSC0437.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Square Top</td>\n",
       "      <td>Marble</td>\n",
       "      <td>ERECTED\\n- to the Memory of\\n- [unclear text]\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_DSC0421.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Square Top</td>\n",
       "      <td>Slate</td>\n",
       "      <td>In Memory\\n-of\\n-SARAH THURBER\\n-BENSON,\\n-rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.DS_Store</td>\n",
       "      <td>I don't see any image attached to your message...</td>\n",
       "      <td>I don't see an image of a gravestone in your m...</td>\n",
       "      <td>I don't see an image of a gravestone in your m...</td>\n",
       "      <td>I don't see any image attached to your message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_DSC0420.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Square Top</td>\n",
       "      <td>Slate</td>\n",
       "      <td>In Memory\\nof\\nFRANCES BENSON\\neldest daughter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_DSC0416.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Square Top</td>\n",
       "      <td>Slate</td>\n",
       "      <td>In Memory\\n-of\\n-HENRY E. BENSON,\\n-youngest s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Image Name                            Iconography Description  \\\n",
       "0  _DSC0437.jpeg                                                NaN   \n",
       "1  _DSC0421.jpeg                                                NaN   \n",
       "2      .DS_Store  I don't see any image attached to your message...   \n",
       "3  _DSC0420.jpeg                                                NaN   \n",
       "4  _DSC0416.jpeg                                                NaN   \n",
       "\n",
       "                                   Shape Description  \\\n",
       "0                                         Square Top   \n",
       "1                                         Square Top   \n",
       "2  I don't see an image of a gravestone in your m...   \n",
       "3                                         Square Top   \n",
       "4                                         Square Top   \n",
       "\n",
       "                                            Material  \\\n",
       "0                                             Marble   \n",
       "1                                              Slate   \n",
       "2  I don't see an image of a gravestone in your m...   \n",
       "3                                              Slate   \n",
       "4                                              Slate   \n",
       "\n",
       "                                Claude Transcription  \n",
       "0  ERECTED\\n- to the Memory of\\n- [unclear text]\\...  \n",
       "1  In Memory\\n-of\\n-SARAH THURBER\\n-BENSON,\\n-rel...  \n",
       "2  I don't see any image attached to your message...  \n",
       "3  In Memory\\nof\\nFRANCES BENSON\\neldest daughter...  \n",
       "4  In Memory\\n-of\\n-HENRY E. BENSON,\\n-youngest s...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc = pd.read_csv(OUTPUT_FOLDER + \"results.csv\", index_col=0)\n",
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8bcc4",
   "metadata": {},
   "source": [
    "### Get Data from Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d885b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! The following is a transcription from a gravestone. Each line is separated by a newline character.Can you tell me the first name, middle name, last name, date of birth, date of death, age at death.The information will not be labeled. You might have to calculate age on death, birth year, or death year based on the other two. If there is information missing for a field, put None. Please only return exactly the information requested, in order separated by a comma. Only do this for the first person if there are multiple. Do not say anything else in your answer. Here is the Transcription: ERECTED\n",
      "- to the Memory of\n",
      "- [unclear text]\n",
      "- In the 46th year\n",
      "- WILLIAM McDONALD\n",
      "- & daughter of\n",
      "- JAMES BERKSHIRE\n",
      "- She died\n",
      "- Aug 30-1856\n",
      "- in the 33d year\n",
      "- of her age\n",
      "=== DEBUG INFO ===\n",
      "URL: https://api.anthropic.com/v1/messages\n",
      "Method: POST\n",
      "Headers:\n",
      "  Content-Type: application/json\n",
      "  x-api-key: sk-ant-api...\n",
      "  anthropic-version: 2023-06-01\n",
      "Data keys: ['model', 'max_tokens', 'messages']\n",
      "Model: claude-sonnet-4-20250514\n",
      "Message type: <class 'list'>\n",
      "===================\n",
      "Response status: 200\n",
      "Response headers: {'Date': 'Tue, 19 Aug 2025 22:54:03 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Content-Encoding': 'gzip', 'anthropic-ratelimit-input-tokens-limit': '30000', 'anthropic-ratelimit-input-tokens-remaining': '30000', 'anthropic-ratelimit-input-tokens-reset': '2025-08-19T22:54:03Z', 'anthropic-ratelimit-output-tokens-limit': '8000', 'anthropic-ratelimit-output-tokens-remaining': '8000', 'anthropic-ratelimit-output-tokens-reset': '2025-08-19T22:54:03Z', 'anthropic-ratelimit-requests-limit': '50', 'anthropic-ratelimit-requests-remaining': '49', 'anthropic-ratelimit-requests-reset': '2025-08-19T22:54:03Z', 'anthropic-ratelimit-tokens-limit': '38000', 'anthropic-ratelimit-tokens-remaining': '38000', 'anthropic-ratelimit-tokens-reset': '2025-08-19T22:54:03Z', 'request-id': 'req_011CSHtdhULpPdSCWBmCBP1s', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'anthropic-organization-id': 'e151097a-17b2-411e-ab82-5aa725fca33c', 'x-envoy-upstream-service-time': '1241', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'X-Robots-Tag': 'none', 'Server': 'cloudflare', 'CF-RAY': '971d3aff7ad432cc-PHL'}\n",
      "Hi! The following is a transcription from a gravestone. Each line is separated by a newline character.Can you tell me the first name, middle name, last name, date of birth, date of death, age at death.The information will not be labeled. You might have to calculate age on death, birth year, or death year based on the other two. If there is information missing for a field, put None. Please only return exactly the information requested, in order separated by a comma. Only do this for the first person if there are multiple. Do not say anything else in your answer. Here is the Transcription: In Memory\n",
      "-of\n",
      "-SARAH THURBER\n",
      "-BENSON,\n",
      "-relict of\n",
      "-GEORGE BENSON,\n",
      "-who died Aug: 25,\n",
      "-1844,\n",
      "-aged 74 years.\n",
      "=== DEBUG INFO ===\n",
      "URL: https://api.anthropic.com/v1/messages\n",
      "Method: POST\n",
      "Headers:\n",
      "  Content-Type: application/json\n",
      "  x-api-key: sk-ant-api...\n",
      "  anthropic-version: 2023-06-01\n",
      "Data keys: ['model', 'max_tokens', 'messages']\n",
      "Model: claude-sonnet-4-20250514\n",
      "Message type: <class 'list'>\n",
      "===================\n",
      "Response status: 200\n",
      "Response headers: {'Date': 'Tue, 19 Aug 2025 22:54:06 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Content-Encoding': 'gzip', 'anthropic-ratelimit-input-tokens-limit': '30000', 'anthropic-ratelimit-input-tokens-remaining': '30000', 'anthropic-ratelimit-input-tokens-reset': '2025-08-19T22:54:06Z', 'anthropic-ratelimit-output-tokens-limit': '8000', 'anthropic-ratelimit-output-tokens-remaining': '8000', 'anthropic-ratelimit-output-tokens-reset': '2025-08-19T22:54:06Z', 'anthropic-ratelimit-requests-limit': '50', 'anthropic-ratelimit-requests-remaining': '49', 'anthropic-ratelimit-requests-reset': '2025-08-19T22:54:06Z', 'anthropic-ratelimit-tokens-limit': '38000', 'anthropic-ratelimit-tokens-remaining': '38000', 'anthropic-ratelimit-tokens-reset': '2025-08-19T22:54:06Z', 'request-id': 'req_011CSHtdwnp62M3Dx7PmhGz3', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'anthropic-organization-id': 'e151097a-17b2-411e-ab82-5aa725fca33c', 'x-envoy-upstream-service-time': '1156', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'X-Robots-Tag': 'none', 'Server': 'cloudflare', 'CF-RAY': '971d3b145c6732d2-PHL'}\n",
      "Hi! The following is a transcription from a gravestone. Each line is separated by a newline character.Can you tell me the first name, middle name, last name, date of birth, date of death, age at death.The information will not be labeled. You might have to calculate age on death, birth year, or death year based on the other two. If there is information missing for a field, put None. Please only return exactly the information requested, in order separated by a comma. Only do this for the first person if there are multiple. Do not say anything else in your answer. Here is the Transcription: I don't see any image attached to your message. Could you please share the gravestone image you'd like me to transcribe?\n",
      "=== DEBUG INFO ===\n",
      "URL: https://api.anthropic.com/v1/messages\n",
      "Method: POST\n",
      "Headers:\n",
      "  Content-Type: application/json\n",
      "  x-api-key: sk-ant-api...\n",
      "  anthropic-version: 2023-06-01\n",
      "Data keys: ['model', 'max_tokens', 'messages']\n",
      "Model: claude-sonnet-4-20250514\n",
      "Message type: <class 'list'>\n",
      "===================\n",
      "Response status: 200\n",
      "Response headers: {'Date': 'Tue, 19 Aug 2025 22:54:10 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Content-Encoding': 'gzip', 'anthropic-ratelimit-input-tokens-limit': '30000', 'anthropic-ratelimit-input-tokens-remaining': '30000', 'anthropic-ratelimit-input-tokens-reset': '2025-08-19T22:54:09Z', 'anthropic-ratelimit-output-tokens-limit': '8000', 'anthropic-ratelimit-output-tokens-remaining': '8000', 'anthropic-ratelimit-output-tokens-reset': '2025-08-19T22:54:10Z', 'anthropic-ratelimit-requests-limit': '50', 'anthropic-ratelimit-requests-remaining': '49', 'anthropic-ratelimit-requests-reset': '2025-08-19T22:54:10Z', 'anthropic-ratelimit-tokens-limit': '38000', 'anthropic-ratelimit-tokens-remaining': '38000', 'anthropic-ratelimit-tokens-reset': '2025-08-19T22:54:09Z', 'request-id': 'req_011CSHteBhE7KAnW8us8GU96', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'anthropic-organization-id': 'e151097a-17b2-411e-ab82-5aa725fca33c', 'x-envoy-upstream-service-time': '1687', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'X-Robots-Tag': 'none', 'Server': 'cloudflare', 'CF-RAY': '971d3b28ccf26992-PHL'}\n",
      "[Retry 1/3] Error with transcription:\n",
      "I don't see any image attached to your message. Could you please share the gravestone image you'd like me to transcribe?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/djfiume/Desktop/DSI/2050/nbg_gravestone_pipeline/code/llm_helper_functions.py\", line 277, in transcription_info\n",
      "    break  # success\n",
      "ValueError: Expected 6 fields, got 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! The following is a transcription from a gravestone. Each line is separated by a newline character.Can you tell me the first name, middle name, last name, date of birth, date of death, age at death.The information will not be labeled. You might have to calculate age on death, birth year, or death year based on the other two. If there is information missing for a field, put None. Please only return exactly the information requested, in order separated by a comma. Only do this for the first person if there are multiple. Do not say anything else in your answer. Here is the Transcription: I don't see any image attached to your message. Could you please share the gravestone image you'd like me to transcribe?\n",
      "=== DEBUG INFO ===\n",
      "URL: https://api.anthropic.com/v1/messages\n",
      "Method: POST\n",
      "Headers:\n",
      "  Content-Type: application/json\n",
      "  x-api-key: sk-ant-api...\n",
      "  anthropic-version: 2023-06-01\n",
      "Data keys: ['model', 'max_tokens', 'messages']\n",
      "Model: claude-sonnet-4-20250514\n",
      "Message type: <class 'list'>\n",
      "===================\n",
      "Response status: 200\n",
      "Response headers: {'Date': 'Tue, 19 Aug 2025 22:54:16 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Content-Encoding': 'gzip', 'anthropic-ratelimit-input-tokens-limit': '30000', 'anthropic-ratelimit-input-tokens-remaining': '30000', 'anthropic-ratelimit-input-tokens-reset': '2025-08-19T22:54:15Z', 'anthropic-ratelimit-output-tokens-limit': '8000', 'anthropic-ratelimit-output-tokens-remaining': '8000', 'anthropic-ratelimit-output-tokens-reset': '2025-08-19T22:54:16Z', 'anthropic-ratelimit-requests-limit': '50', 'anthropic-ratelimit-requests-remaining': '49', 'anthropic-ratelimit-requests-reset': '2025-08-19T22:54:15Z', 'anthropic-ratelimit-tokens-limit': '38000', 'anthropic-ratelimit-tokens-remaining': '38000', 'anthropic-ratelimit-tokens-reset': '2025-08-19T22:54:15Z', 'request-id': 'req_011CSHtecNHoxQMCnybQTgif', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'anthropic-organization-id': 'e151097a-17b2-411e-ab82-5aa725fca33c', 'x-envoy-upstream-service-time': '2051', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'X-Robots-Tag': 'none', 'Server': 'cloudflare', 'CF-RAY': '971d3b4cd9164cb4-PHL'}\n",
      "[Retry 2/3] Error with transcription:\n",
      "I don't see any image attached to your message. Could you please share the gravestone image you'd like me to transcribe?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/djfiume/Desktop/DSI/2050/nbg_gravestone_pipeline/code/llm_helper_functions.py\", line 277, in transcription_info\n",
      "    break  # success\n",
      "ValueError: Expected 6 fields, got 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! The following is a transcription from a gravestone. Each line is separated by a newline character.Can you tell me the first name, middle name, last name, date of birth, date of death, age at death.The information will not be labeled. You might have to calculate age on death, birth year, or death year based on the other two. If there is information missing for a field, put None. Please only return exactly the information requested, in order separated by a comma. Only do this for the first person if there are multiple. Do not say anything else in your answer. Here is the Transcription: I don't see any image attached to your message. Could you please share the gravestone image you'd like me to transcribe?\n",
      "=== DEBUG INFO ===\n",
      "URL: https://api.anthropic.com/v1/messages\n",
      "Method: POST\n",
      "Headers:\n",
      "  Content-Type: application/json\n",
      "  x-api-key: sk-ant-api...\n",
      "  anthropic-version: 2023-06-01\n",
      "Data keys: ['model', 'max_tokens', 'messages']\n",
      "Model: claude-sonnet-4-20250514\n",
      "Message type: <class 'list'>\n",
      "===================\n",
      "Response status: 200\n",
      "Response headers: {'Date': 'Tue, 19 Aug 2025 22:54:22 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Content-Encoding': 'gzip', 'anthropic-ratelimit-input-tokens-limit': '30000', 'anthropic-ratelimit-input-tokens-remaining': '30000', 'anthropic-ratelimit-input-tokens-reset': '2025-08-19T22:54:21Z', 'anthropic-ratelimit-output-tokens-limit': '8000', 'anthropic-ratelimit-output-tokens-remaining': '8000', 'anthropic-ratelimit-output-tokens-reset': '2025-08-19T22:54:22Z', 'anthropic-ratelimit-requests-limit': '50', 'anthropic-ratelimit-requests-remaining': '49', 'anthropic-ratelimit-requests-reset': '2025-08-19T22:54:21Z', 'anthropic-ratelimit-tokens-limit': '38000', 'anthropic-ratelimit-tokens-remaining': '38000', 'anthropic-ratelimit-tokens-reset': '2025-08-19T22:54:21Z', 'request-id': 'req_011CSHtf4oWpAwJPMvTP3bAJ', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'anthropic-organization-id': 'e151097a-17b2-411e-ab82-5aa725fca33c', 'x-envoy-upstream-service-time': '1844', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'X-Robots-Tag': 'none', 'Server': 'cloudflare', 'CF-RAY': '971d3b737ae06992-PHL'}\n",
      "[Retry 3/3] Error with transcription:\n",
      "I don't see any image attached to your message. Could you please share the gravestone image you'd like me to transcribe?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/djfiume/Desktop/DSI/2050/nbg_gravestone_pipeline/code/llm_helper_functions.py\", line 277, in transcription_info\n",
      "    break  # success\n",
      "ValueError: Expected 6 fields, got 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! The following is a transcription from a gravestone. Each line is separated by a newline character.Can you tell me the first name, middle name, last name, date of birth, date of death, age at death.The information will not be labeled. You might have to calculate age on death, birth year, or death year based on the other two. If there is information missing for a field, put None. Please only return exactly the information requested, in order separated by a comma. Only do this for the first person if there are multiple. Do not say anything else in your answer. Here is the Transcription: In Memory\n",
      "of\n",
      "FRANCES BENSON\n",
      "eldest daughter of\n",
      "George & Sarah Benson\n",
      "Born in Providence\n",
      "July 21 1794\n",
      "Died at Brooklyn Conn\n",
      "Oct 31 1832\n",
      "Aged 38 years\n",
      "=== DEBUG INFO ===\n",
      "URL: https://api.anthropic.com/v1/messages\n",
      "Method: POST\n",
      "Headers:\n",
      "  Content-Type: application/json\n",
      "  x-api-key: sk-ant-api...\n",
      "  anthropic-version: 2023-06-01\n",
      "Data keys: ['model', 'max_tokens', 'messages']\n",
      "Model: claude-sonnet-4-20250514\n",
      "Message type: <class 'list'>\n",
      "===================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_info \u001b[38;5;241m=\u001b[39m \u001b[43mtranscription_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_desc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClaude Transcription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mINFO_PROMPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mINFO_COLUMNS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHEADERS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_all \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_desc, df_info])\n\u001b[1;32m      3\u001b[0m df_all\u001b[38;5;241m.\u001b[39mto_csv(OUTPUT_FOLDER \u001b[38;5;241m+\u001b[39m OUTPUT_FILENAME, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/DSI/2050/nbg_gravestone_pipeline/code/llm_helper_functions.py:266\u001b[0m, in \u001b[0;36mtranscription_info\u001b[0;34m(transcriptions, prompt, columns, headers, debug, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    263\u001b[0m full_prompt \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m+\u001b[39m trans\n\u001b[1;32m    264\u001b[0m result \u001b[38;5;241m=\u001b[39m call_claude(full_prompt, headers\u001b[38;5;241m=\u001b[39mheaders, debug\u001b[38;5;241m=\u001b[39mdebug)\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMalformed Claude response or empty content\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m text \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/DSI/2050/nbg_gravestone_pipeline/code/llm_helper_functions.py:160\u001b[0m, in \u001b[0;36mcall_claude\u001b[0;34m(prompt, headers, image_path, model, debug)\u001b[0m\n\u001b[1;32m    158\u001b[0m     debug_request(data, headers)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAPI_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/DSI/2050/nbg_gravestone_pipeline/venv/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/DSI/2050/nbg_gravestone_pipeline/venv/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/DSI/2050/nbg_gravestone_pipeline/venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Desktop/DSI/2050/nbg_gravestone_pipeline/venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Desktop/DSI/2050/nbg_gravestone_pipeline/venv/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Desktop/DSI/2050/nbg_gravestone_pipeline/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DSI/2050/nbg_gravestone_pipeline/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/Desktop/DSI/2050/nbg_gravestone_pipeline/venv/lib/python3.10/site-packages/urllib3/connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_info = transcription_info(df_desc[\"Claude Transcription\"], INFO_PROMPT, INFO_COLUMNS, HEADERS, debug=True)\n",
    "df_all = pd.concat([df_desc, df_info])\n",
    "df_all.to_csv(OUTPUT_FOLDER + OUTPUT_FILENAME, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d6902a",
   "metadata": {},
   "source": [
    "## OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a7bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting easyocr\n",
      "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.5 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (0.17.2)\n",
      "Collecting opencv-python-headless (from easyocr)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-macosx_13_0_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: scipy in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (1.14.1)\n",
      "Requirement already satisfied: numpy in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (2.2.6)\n",
      "Requirement already satisfied: Pillow in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (10.4.0)\n",
      "Collecting scikit-image (from easyocr)\n",
      "  Downloading scikit_image-0.25.2-cp312-cp312-macosx_10_13_x86_64.whl.metadata (14 kB)\n",
      "Collecting python-bidi (from easyocr)\n",
      "  Downloading python_bidi-0.6.6-cp312-cp312-macosx_10_12_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: PyYAML in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from easyocr) (6.0.2)\n",
      "Collecting Shapely (from easyocr)\n",
      "  Downloading shapely-2.1.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting pyclipper (from easyocr)\n",
      "  Downloading pyclipper-1.3.0.post6-cp312-cp312-macosx_10_13_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting ninja (from easyocr)\n",
      "  Downloading ninja-1.11.1.4-py3-none-macosx_10_9_universal2.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: filelock in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from torch->easyocr) (2024.9.0)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->easyocr)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->easyocr)\n",
      "  Downloading tifffile-2025.6.11-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: packaging>=21 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from scikit-image->easyocr) (24.1)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->easyocr)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from jinja2->torch->easyocr) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/djfiume/opt/miniconda3/envs/data1030/lib/python3.12/site-packages (from sympy->torch->easyocr) (1.3.0)\n",
      "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-macosx_10_9_universal2.whl (279 kB)\n",
      "Downloading opencv_python_headless-4.12.0.88-cp37-abi3-macosx_13_0_x86_64.whl (57.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp312-cp312-macosx_10_13_x86_64.whl (143 kB)\n",
      "Downloading python_bidi-0.6.6-cp312-cp312-macosx_10_12_x86_64.whl (267 kB)\n",
      "Downloading scikit_image-0.25.2-cp312-cp312-macosx_10_13_x86_64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.1.1-cp312-cp312-macosx_10_13_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading tifffile-2025.6.11-py3-none-any.whl (230 kB)\n",
      "Installing collected packages: python-bidi, pyclipper, tifffile, Shapely, opencv-python-headless, ninja, lazy-loader, imageio, scikit-image, easyocr\n",
      "Successfully installed Shapely-2.1.1 easyocr-1.7.2 imageio-2.37.0 lazy-loader-0.4 ninja-1.11.1.4 opencv-python-headless-4.12.0.88 pyclipper-1.3.0.post6 python-bidi-0.6.6 scikit-image-0.25.2 tifffile-2025.6.11\n",
      "Processing _DSC0470.jpeg...\n",
      "Processing _DSC0469.jpeg...\n"
     ]
    }
   ],
   "source": [
    "# Old OCR model - not good, but you can run it if curious \n",
    "# df = tesseract_ocr(INPUT_FOLDER)\n",
    "df = process_easy_ocr(INPUT_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310a6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing _DSC0421.jpeg...\n",
      "\n",
      "🔎 OCR Output:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (e00002bd:Internal Error)\n",
      "\t<GFX10_MtlCmdBuffer: 0x7f90827b1e00>\n",
      "    label = <none> \n",
      "    device = <GFX10_MtlDevice: 0x7f90759d0000>\n",
      "        name = AMD Radeon Pro 5500M \n",
      "    commandQueue = <GFXAAMD_MtlCmdQueue: 0x7f91973c0d00>\n",
      "        label = <none> \n",
      "        device = <GFX10_MtlDevice: 0x7f90759d0000>\n",
      "            name = AMD Radeon Pro 5500M \n",
      "    retainedReferences = 1\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(OUTPUT_FOLDER + \"ocr_results.csv\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
